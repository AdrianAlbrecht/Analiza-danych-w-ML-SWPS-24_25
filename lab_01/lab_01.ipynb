{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 01 - Wstęp do ML, podział danych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trochę wstępu na początek"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Czym jest Machine Learning (ML)?\n",
    "\n",
    "**Machine Learning (Uczenie Maszynowe)** to dziedzina sztucznej inteligencji (AI), która koncentruje się na tworzeniu algorytmów i modeli, które mogą samodzielnie uczyć się na podstawie danych. Celem ML jest wykorzystanie danych do prognozowania, klasyfikacji, wykrywania wzorców i podejmowania decyzji bez potrzeby programowania reguł na sztywno. Modele ML uczą się na podstawie przykładów i wzorców, zamiast stosować twarde reguły, co pozwala im działać efektywnie w dynamicznych i skomplikowanych środowiskach.\n",
    "\n",
    "Przykładowe zastosowania ML to:\n",
    "- Rozpoznawanie obrazów i dźwięków,\n",
    "- Systemy rekomendacyjne (np. Netflix, Amazon),\n",
    "- Wykrywanie oszustw (fraud detection, spam detection),\n",
    "- Modele prognozujące np. ceny akcji czy zachowania użytkowników.\n",
    "\n",
    "### Analiza Danych w Machine Learning\n",
    "\n",
    "**Analiza Danych** w kontekście Machine Learning jest kluczowym procesem, który polega na przygotowaniu, eksploracji i interpretacji danych, na których model ML będzie się uczył. Proces ten jest ważny, ponieważ jakość danych bezpośrednio wpływa na efektywność modelu. Analiza danych obejmuje kilka istotnych kroków:\n",
    "\n",
    "1. **Zbieranie Danych**: Dane są sercem każdego modelu ML. Mogą pochodzić z różnych źródeł, takich jak bazy danych, pliki CSV, strumienie danych z czujników itp.\n",
    "   \n",
    "2. **Czyszczenie Danych**: Dane często zawierają braki, błędy lub niespójności. Proces czyszczenia obejmuje usuwanie brakujących wartości, eliminację duplikatów oraz korektę błędów w danych.\n",
    "\n",
    "3. **Eksploracja Danych**: Przed stworzeniem modelu konieczne jest zrozumienie danych. Eksploracja obejmuje wizualizację danych, analizę rozkładów zmiennych, identyfikację zależności między cechami oraz wyszukiwanie anomalii.\n",
    "\n",
    "4. **Inżynieria Cech (Feature Engineering)**: Ważnym etapem jest przekształcenie surowych danych w cechy (ang. features), które będą używane przez model ML. Obejmuje to tworzenie nowych cech na podstawie istniejących, standaryzację, normalizację, kodowanie zmiennych kategorialnych itp.\n",
    "\n",
    "5. **Podział Danych**: Dane dzielimy na zbiory treningowe, walidacyjne i testowe, aby ocenić, jak dobrze model generalizuje się na nowych, niewidzianych wcześniej danych.\n",
    "\n",
    "6. **Analiza wyników**: Po trenowaniu modelu, analiza wyników (na przykład analiza metryk takich jak dokładność, precyzja, czułość) pozwala ocenić, jak dobrze model radzi sobie z zadaniem.\n",
    "\n",
    "### Znaczenie Analizy Danych w ML\n",
    "\n",
    "W ML jakość danych i sposób ich przetwarzania ma kluczowe znaczenie. Nawet najlepsze algorytmy nie będą działały prawidłowo, jeśli dane będą nieodpowiednio przygotowane. Dlatego analiza danych stanowi niezbędny element całego procesu budowy modeli ML.\n",
    "\n",
    "Proces Machine Learning z zaawansowaną analizą danych jest wykorzystywany w różnych branżach, m.in. w finansach, marketingu, medycynie czy inżynierii.\n",
    "\n",
    "Cały proces obróbki danych przed dopuszczeniem ich do modelu jest bardzo czxęsto najbardziej czasochłonnym i złożonym zestawem opracji w trakcie tworzenia modelu... Dlatego zacznijmy od czegoś łatwego."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Podział danych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W procesie uczenia maszynowego (ML) dane są zazwyczaj dzielone na różne zbiory w celu trenowania, walidacji i testowania modeli. Oto najczęstsze przykłady podziału danych:\n",
    "\n",
    "### 1. **Podział na zbiór treningowy i testowy (Train-Test Split)**\n",
    "\n",
    "Najprostszy i najczęściej stosowany podział, w którym dane dzieli się na dwa zbiory:\n",
    "- **Zbiór treningowy (Training Set)**: Służy do trenowania modelu. Model uczy się na tych danych, analizując wzorce i zależności.\n",
    "- **Zbiór testowy (Test Set)**: Wykorzystywany do oceny modelu po zakończeniu treningu, aby sprawdzić, jak dobrze generalizuje na nowych, niewidzianych wcześniej danych.\n",
    "\n",
    "Typowy podział to **80% danych na trening i 20% na test**, choć wartości te mogą się różnić (np. 70/30 lub 90/10), w zależności od rozmiaru dostępnych danych. W skrajnej sytuacji, gdy mamy mało danych podział 90/10 może zaskutkować, że w zbiorze treningowym będziemy mieli jedynie jeden rekord, co w praktyce daj nam tylko dwie możliwości: 100% poprawności działania modelu bądź 0%. Oczywiście unikamy takich sytuacji, dlatego ważne jest odpowiednie dobranie podziału danych jednocześnie dążać do jak największej ilości danych (zważając również na ich jakość).\n",
    "\n",
    "### 2. **Podział na zbiór treningowy, walidacyjny i testowy (Train-Validation-Test Split)**\n",
    "\n",
    "Aby uzyskać bardziej precyzyjną ocenę modelu i zoptymalizować jego hiperparametry, wprowadza się dodatkowy zbiór:\n",
    "- **Zbiór treningowy (Training Set)**: Używany do trenowania modelu.\n",
    "- **Zbiór walidacyjny (Validation Set)**: Służy do optymalizacji hiperparametrów oraz wyboru najlepszego modelu. Dane te są używane do testowania modelu w trakcie trenowania, ale nie są wykorzystywane bezpośrednio w uczeniu.\n",
    "- **Zbiór testowy (Test Set)**: Używany do ostatecznej oceny modelu po zakończeniu jego trenowania.\n",
    "\n",
    "Typowy podział to np. **70% trening, 15% walidacja i 15% test**, ale wartości mogą się różnić w zależności od ilości danych.\n",
    "\n",
    "Można z łatwością dokonać manualnej implementacji funkcji/metody odpowiedzialnej za dokonanie podziału, lecz znacznie lepszą drogą będzie wykorzystanie dostępnych (i przetestowanych) implementacji dostarczanych za pomocą bibliotek."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit-learn\n",
    "\n",
    "Biblioteka [scikit-learn](https://pypi.org/project/scikit-learn/) jest jednym z najczęściej stosowanych pakietów przez badaczy danych. Scikit-learn nie wchodzi w skład biblioteki standardowej, zatem trzeba ją doinstalować manualnie. W przypadku korzystania ze środowisk Colab lub Conda, implementacja zwykle jest już zainstalowana automatycznie w każdym nowym środowisku roboczym."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Biblioteka scikit-learn - oprócz implementacji funkcji służących do podziału danych - dostarcza także metody przetwarzania i uzupełniania informacji, a także implementacje popularnych algorytmów uczenia maszynowego. Ciekawą funkcjonalnością biblioteki scikit-learn jest zautomatyzowane udostępnianie popularnych (rzeczywistych) zbiorów danych bez konieczności ich manualnego pobierania i rozpakowywania. Pełna lista dostępna jest pod adresem: [https://scikit-learn.org/stable/datasets.html](https://scikit-learn.org/stable/datasets.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pobieranie danych za pomocą biblioteki scikit-learn\n",
    "\n",
    "Do pobierania zbiorów danych przeznaczone są funkcje sprecyzowane w podstronach poświęconych każdemu ze zbiorów. Przykładowo, dla zbioru California Housing ([https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset](https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset)) przeznaczona jest funkcja fetch_california_housing dostępna w module *datasets* pakietu *sklearn*.\n",
    "\n",
    "Domyślnie zwracany jest słownik zawierający tablice wartości będące atrybutami. Przekazując do funkcji parametr *as_frame* o wartości logicznej *True*, zostanie zwrócony zbiór danych w postaci ramki danych *pandas* dostępne w kluczu *frame* wynikowego słownika."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>MedHouseVal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20635</th>\n",
       "      <td>1.5603</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.045455</td>\n",
       "      <td>1.133333</td>\n",
       "      <td>845.0</td>\n",
       "      <td>2.560606</td>\n",
       "      <td>39.48</td>\n",
       "      <td>-121.09</td>\n",
       "      <td>0.781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20636</th>\n",
       "      <td>2.5568</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6.114035</td>\n",
       "      <td>1.315789</td>\n",
       "      <td>356.0</td>\n",
       "      <td>3.122807</td>\n",
       "      <td>39.49</td>\n",
       "      <td>-121.21</td>\n",
       "      <td>0.771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20637</th>\n",
       "      <td>1.7000</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.205543</td>\n",
       "      <td>1.120092</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>2.325635</td>\n",
       "      <td>39.43</td>\n",
       "      <td>-121.22</td>\n",
       "      <td>0.923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20638</th>\n",
       "      <td>1.8672</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.329513</td>\n",
       "      <td>1.171920</td>\n",
       "      <td>741.0</td>\n",
       "      <td>2.123209</td>\n",
       "      <td>39.43</td>\n",
       "      <td>-121.32</td>\n",
       "      <td>0.847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20639</th>\n",
       "      <td>2.3886</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.254717</td>\n",
       "      <td>1.162264</td>\n",
       "      <td>1387.0</td>\n",
       "      <td>2.616981</td>\n",
       "      <td>39.37</td>\n",
       "      <td>-121.24</td>\n",
       "      <td>0.894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20640 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0      8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1      8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2      7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3      5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4      3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "...       ...       ...       ...        ...         ...       ...       ...   \n",
       "20635  1.5603      25.0  5.045455   1.133333       845.0  2.560606     39.48   \n",
       "20636  2.5568      18.0  6.114035   1.315789       356.0  3.122807     39.49   \n",
       "20637  1.7000      17.0  5.205543   1.120092      1007.0  2.325635     39.43   \n",
       "20638  1.8672      18.0  5.329513   1.171920       741.0  2.123209     39.43   \n",
       "20639  2.3886      16.0  5.254717   1.162264      1387.0  2.616981     39.37   \n",
       "\n",
       "       Longitude  MedHouseVal  \n",
       "0        -122.23        4.526  \n",
       "1        -122.22        3.585  \n",
       "2        -122.24        3.521  \n",
       "3        -122.25        3.413  \n",
       "4        -122.25        3.422  \n",
       "...          ...          ...  \n",
       "20635    -121.09        0.781  \n",
       "20636    -121.21        0.771  \n",
       "20637    -121.22        0.923  \n",
       "20638    -121.32        0.847  \n",
       "20639    -121.24        0.894  \n",
       "\n",
       "[20640 rows x 9 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = fetch_california_housing(as_frame=True)['frame']\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>MedHouseVal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.0368</td>\n",
       "      <td>52.0</td>\n",
       "      <td>4.761658</td>\n",
       "      <td>1.103627</td>\n",
       "      <td>413.0</td>\n",
       "      <td>2.139896</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>2.697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.6591</td>\n",
       "      <td>52.0</td>\n",
       "      <td>4.931907</td>\n",
       "      <td>0.951362</td>\n",
       "      <td>1094.0</td>\n",
       "      <td>2.128405</td>\n",
       "      <td>37.84</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>2.992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.1200</td>\n",
       "      <td>52.0</td>\n",
       "      <td>4.797527</td>\n",
       "      <td>1.061824</td>\n",
       "      <td>1157.0</td>\n",
       "      <td>1.788253</td>\n",
       "      <td>37.84</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>2.414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.0804</td>\n",
       "      <td>42.0</td>\n",
       "      <td>4.294118</td>\n",
       "      <td>1.117647</td>\n",
       "      <td>1206.0</td>\n",
       "      <td>2.026891</td>\n",
       "      <td>37.84</td>\n",
       "      <td>-122.26</td>\n",
       "      <td>2.267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.6912</td>\n",
       "      <td>52.0</td>\n",
       "      <td>4.970588</td>\n",
       "      <td>0.990196</td>\n",
       "      <td>1551.0</td>\n",
       "      <td>2.172269</td>\n",
       "      <td>37.84</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>2.611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "5  4.0368      52.0  4.761658   1.103627       413.0  2.139896     37.85   \n",
       "6  3.6591      52.0  4.931907   0.951362      1094.0  2.128405     37.84   \n",
       "7  3.1200      52.0  4.797527   1.061824      1157.0  1.788253     37.84   \n",
       "8  2.0804      42.0  4.294118   1.117647      1206.0  2.026891     37.84   \n",
       "9  3.6912      52.0  4.970588   0.990196      1551.0  2.172269     37.84   \n",
       "\n",
       "   Longitude  MedHouseVal  \n",
       "0    -122.23        4.526  \n",
       "1    -122.22        3.585  \n",
       "2    -122.24        3.521  \n",
       "3    -122.25        3.413  \n",
       "4    -122.25        3.422  \n",
       "5    -122.25        2.697  \n",
       "6    -122.25        2.992  \n",
       "7    -122.25        2.414  \n",
       "8    -122.26        2.267  \n",
       "9    -122.25        2.611  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup',\n",
       "       'Latitude', 'Longitude', 'MedHouseVal'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MedInc         float64\n",
       "HouseAge       float64\n",
       "AveRooms       float64\n",
       "AveBedrms      float64\n",
       "Population     float64\n",
       "AveOccup       float64\n",
       "Latitude       float64\n",
       "Longitude      float64\n",
       "MedHouseVal    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>MedHouseVal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "\n",
       "   Longitude  MedHouseVal  \n",
       "0    -122.23        4.526  \n",
       "1    -122.22        3.585  \n",
       "2    -122.24        3.521  \n",
       "3    -122.25        3.413  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Longitude</th>\n",
       "      <th>MedHouseVal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Longitude  MedHouseVal\n",
       "0    -122.23        4.526\n",
       "1    -122.22        3.585\n",
       "2    -122.24        3.521\n",
       "3    -122.25        3.413"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[:4,-2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Podział danych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Podział prosty\n",
    "\n",
    "Do dokonania podziału prostego przeznaczona jest funkcja *train_test_split* znajdująca się w module *model_selection* pakietu *sklearn*. Najważniejsze parametry przyjmowane przez funkcję to:\n",
    "- (nienazwane) tablice NumPy z atrybutami warunkowymi oraz opcjonalnie z atrybutem decyzyjnym,\n",
    "- test_size: odsetek stanowiący rozmiar danych testowych,\n",
    "- random_state: ziarno losowości. Pozwala nam na \"stały\" podział zbioru, tzn. każde wykonanie kodu z tym samym ziarnem da taki sam efekt.\n",
    "\n",
    "Wynikiem funkcji będą dwie (dla jednej przekazanej tablicy wejściowej z danymi- tylko cechy) lub cztery (dla dwóch tablic wejściowych- cechy i klasy) tablice stanowiące podział danych wejściowych na dane treningowe i testowe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podział prosty atrybutów warunkowych można przeprowadzić przekazując tylko jedną tablicę wejściową. Podział zostanie przeprowadzony w stosunku 80%:20% odpowiednio dla podzbioru treningowego i testowego. Parametr *test_size* określamy w liczbie zmiennoprzecinkowej w zakresie (0,1), która określa wielkość zbioru testowego- tj. 0.2 oznacza, że zbiór testowy będzie zawierał 20% wielkości zbioru wejściowego."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3],\n",
       "       [ 4,  5,  6,  7],\n",
       "       [ 8,  9, 10, 11],\n",
       "       [12, 13, 14, 15],\n",
       "       [16, 17, 18, 19],\n",
       "       [20, 21, 22, 23],\n",
       "       [24, 25, 26, 27],\n",
       "       [28, 29, 30, 31],\n",
       "       [32, 33, 34, 35],\n",
       "       [36, 37, 38, 39],\n",
       "       [40, 41, 42, 43],\n",
       "       [44, 45, 46, 47],\n",
       "       [48, 49, 50, 51],\n",
       "       [52, 53, 54, 55],\n",
       "       [56, 57, 58, 59],\n",
       "       [60, 61, 62, 63],\n",
       "       [64, 65, 66, 67],\n",
       "       [68, 69, 70, 71],\n",
       "       [72, 73, 74, 75],\n",
       "       [76, 77, 78, 79]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.arange(80).reshape((20, 4))  # tablica zawierajace atrybuty warunkowe\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[48 49 50 51]\n",
      " [52 53 54 55]\n",
      " [ 8  9 10 11]\n",
      " [40 41 42 43]\n",
      " [32 33 34 35]\n",
      " [68 69 70 71]\n",
      " [64 65 66 67]\n",
      " [56 57 58 59]\n",
      " [ 4  5  6  7]\n",
      " [16 17 18 19]\n",
      " [ 0  1  2  3]\n",
      " [76 77 78 79]\n",
      " [12 13 14 15]\n",
      " [28 29 30 31]\n",
      " [24 25 26 27]\n",
      " [60 61 62 63]]\n",
      "===============\n",
      "[[44 45 46 47]\n",
      " [36 37 38 39]\n",
      " [20 21 22 23]\n",
      " [72 73 74 75]]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test = train_test_split(X, test_size=0.2)\n",
    "print(X_train, X_test, sep=\"\\n===============\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[28 29 30 31]\n",
      " [48 49 50 51]\n",
      " [68 69 70 71]\n",
      " [40 41 42 43]\n",
      " [ 4  5  6  7]\n",
      " [32 33 34 35]\n",
      " [60 61 62 63]\n",
      " [64 65 66 67]\n",
      " [44 45 46 47]\n",
      " [12 13 14 15]\n",
      " [24 25 26 27]\n",
      " [16 17 18 19]\n",
      " [ 0  1  2  3]\n",
      " [72 73 74 75]\n",
      " [76 77 78 79]\n",
      " [36 37 38 39]]\n",
      "===============\n",
      "[[ 8  9 10 11]\n",
      " [56 57 58 59]\n",
      " [52 53 54 55]\n",
      " [20 21 22 23]]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test = train_test_split(X, test_size=0.2, random_state=39)\n",
    "print(X_train, X_test, sep=\"\\n===============\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X), len(X_train), len(X_test)\n",
    "assert len(X) == len(X_train) + len(X_test)\n",
    "# assert len(X) == len(X_train) + len(X_test) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dla atrybutów warunkowych i atrybutu decyzyjnego podział ten można przeprowadzić analogicznie dodając do funkcji kolejny zbiór."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.arange(80).reshape((20, 4))  # tablica zawierajace atrybuty warunkowe\n",
    "y = range(20)  # tablica zawierajaca jeden atrybut decyzyjny\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=39)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[28 29 30 31]\n",
      " [48 49 50 51]\n",
      " [68 69 70 71]\n",
      " [40 41 42 43]\n",
      " [ 4  5  6  7]\n",
      " [32 33 34 35]\n",
      " [60 61 62 63]\n",
      " [64 65 66 67]\n",
      " [44 45 46 47]\n",
      " [12 13 14 15]\n",
      " [24 25 26 27]\n",
      " [16 17 18 19]\n",
      " [ 0  1  2  3]\n",
      " [72 73 74 75]\n",
      " [76 77 78 79]\n",
      " [36 37 38 39]]\n",
      "===============\n",
      "[[ 8  9 10 11]\n",
      " [56 57 58 59]\n",
      " [52 53 54 55]\n",
      " [20 21 22 23]]\n",
      "===============\n",
      "[7, 12, 17, 10, 1, 8, 15, 16, 11, 3, 6, 4, 0, 18, 19, 9]\n",
      "===============\n",
      "[2, 14, 13, 5]\n"
     ]
    }
   ],
   "source": [
    "print(X_train, X_test, y_train, y_test, sep=\"\\n===============\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 16, 4, 4)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(y_train), len(X_test), len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przeprowadźmy test- wygenerujmy przykładowe dane gotowe do klasyfikacji binarnej (tj. klasyfikacja, gdzia argue\\ment decyzyjny jedynie wskazuje bądź nie przynależność do jednej z dwóch klas) i podzielmy dane poznaną metodą."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 1 0 0 0 1 1 0 1 0 1 1 0 1 0 0 0 0 0 1 1 0 1 0 0 1 1 1 1 0 0 0 0 0\n",
      " 1 1 1 1 1 0 0 0 1 1 1 0 1 1 1 1 1 0 0 1 0 0 0 0 1 1 0 0 1 0 0 0 1 0 0 1 1\n",
      " 1 1 1 0 1 0]\n",
      "===============\n",
      "[0 1 1 0 0 0 1 1 0 1 1 1 0 1 0 0 1 0 1 1]\n",
      "Wartość 0 występuje 9 razy\n",
      "Wartość 1 występuje 11 razy\n"
     ]
    }
   ],
   "source": [
    "X = np.arange(400).reshape((100, 4))  # tablica zawierajace atrybuty warunkowe\n",
    "y = np.array([0] * 50 + [1] * 50)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "print(y_train, y_test, sep=\"\\n===============\\n\")\n",
    "\n",
    "unique, counts = np.unique(y_test, return_counts=True)\n",
    "for value, count in zip(unique, counts):\n",
    "    print(f\"Wartość {value} występuje {count} razy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przeprowadźmy kolejny eksperyment. Co w przypadku, gdy dane nie są równorozłożone pomiędzy klasy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 0 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 0 0 1 1 1 0 1 0 1 1 1 1\n",
      " 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1 1 1 1 1 1 0 1 1 1\n",
      " 1 0 1 1 1 0]\n",
      "===============\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1]\n",
      "Wartość 0 występuje 2 razy\n",
      "Wartość 1 występuje 18 razy\n"
     ]
    }
   ],
   "source": [
    "X = np.arange(400).reshape((100, 4))  # tablica zawierajace atrybuty warunkowe\n",
    "y = np.array([0] * 20 + [1] * 80)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "print(y_train, y_test, sep=\"\\n===============\\n\")\n",
    "\n",
    "unique, counts = np.unique(y_test, return_counts=True)\n",
    "for value, count in zip(unique, counts):\n",
    "    print(f\"Wartość {value} występuje {count} razy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zmniejszmy teraz wielkość zbioru testowego do 10% i zobaczmy jak zareaguje nasz kod."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1 1 1 0 1 0 0 0 1 1 1\n",
      " 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 1 1 0 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 1\n",
      " 1 0 0 1 0 1 1 1 1 1 1 0 1 1 0 1]\n",
      "===============\n",
      "[1 1 1 1 1 1 1 1 1 1]\n",
      "Wartość 1 występuje 10 razy\n"
     ]
    }
   ],
   "source": [
    "X = np.arange(400).reshape((100, 4))  # tablica zawierajace atrybuty warunkowe\n",
    "y = np.array([0] * 20 + [1] * 80)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "print(y_train, y_test, sep=\"\\n===============\\n\")\n",
    "\n",
    "unique, counts = np.unique(y_test, return_counts=True)\n",
    "for value, count in zip(unique, counts):\n",
    "    print(f\"Wartość {value} występuje {count} razy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W pewnym skrajnym przypadku występuje dość specyficzny przypadek- w zbiorze testowym występuje tylko i wyłącznie jedna z klas- 1 bądź 0 i ilość wystąpień tej klasy jest równoliczna z wielkością zbioru testowego.\n",
    "\n",
    "Warto zatem zauważyć, że istotną wadą podziału prostego jest brak zachowania proporcji względem wybranego atrybutu. Przykładowo, jeżeli w atrybucie decyzyjnym znajdzie się dziesięć zer i dziesięć jedynek, nie mamy kontroli nad tym czy w podzbiorze testowym (o rozmiarze 4) znajdą się same zera, czy dwa zera i dwie jedynki, co jest proporcją zgodną z pełnym oryginalnym zbiorem danym."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Podział warstwowy\n",
    "\n",
    "W bibliotece scikit-learn znajduje się klasa *StratifiedShuffleSplit*, której przeznaczeniem jest dokonywanie wielokrotnych podziałów z zachowaniem proporcji występujących w oryginalnej populacji. Inicjalizator klasy *StratifiedShuffleSplit* przyjmuje następujące parametry:\n",
    "- n_splits: liczba podziałów,\n",
    "- test_size: odsetek obiektów stanowiących podzbiór testowy,\n",
    "- random_state: ziarno losowości.\n",
    "\n",
    "Na obiekcie klasy *StratifiedShuffleSplit* jest dostępna metoda *split*, która przyjmuje parametry w postaci tablicy zawierającej zestaw atrybutów warunkowych oraz tablicy z atrybutem decyzyjnym. Wynikiem funkcji jest iterator, po którym można przeiterować się za pomocą pętli for. Liczba przebiegów będzie zgodna z wartością parametru *n_splits* inicjalizatora klasy *StratifiedShuffleSplit*, a w każdym przebiegu pętli obiekt sterujący będzie stanowiła krota zawierająca dwa elementy: tablicę indeksów obiektów z oryginalnego zbioru danych stanowiącego podzbiór treningowy oraz testowy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na potrzeby przykładu wygenerujemy nowy atrybut decyzyjny, który będzie zawierał wartości 0 i 1 w proporcji 50%:50%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size = len(data)\n",
    "half_data_size = data_size // 2\n",
    "data['decision'] = np.array([0] * half_data_size + [1] * half_data_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wartość 0 występuje 8256 razy\n",
      "Wartość 1 występuje 8256 razy\n",
      "Wartość 0 występuje 2064 razy\n",
      "Wartość 1 występuje 2064 razy\n"
     ]
    }
   ],
   "source": [
    "splitter = StratifiedShuffleSplit(n_splits=10, test_size=0.2)\n",
    "output_col = 'decision'\n",
    "\n",
    "for train_index, test_index in splitter.split(data.loc[:, data.columns != output_col], data[output_col]):\n",
    "    train_data, test_data = data.loc[train_index,output_col], data.loc[test_index,output_col]\n",
    "\n",
    "unique, counts = np.unique(train_data, return_counts=True)\n",
    "for value, count in zip(unique, counts):\n",
    "    print(f\"Wartość {value} występuje {count} razy\")\n",
    "    \n",
    "unique, counts = np.unique(test_data, return_counts=True)\n",
    "for value, count in zip(unique, counts):\n",
    "    print(f\"Wartość {value} występuje {count} razy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadania\n",
    "\n",
    "Zadania odsyłamy w wyznaczonym do tego miejscu na Classromie zajęć w terminie do następnych zajęć (uprzedzając pytania - tak co do godziny). Zadania im wcześniej zostaną przesłane, tym wcześniej zostaną ocenione. *Zadania z błędami należy poprawić.* **Zadania odesłane po terminie nie będą oceniane.**\n",
    "\n",
    "1. Przygotować funkcję get_dataset(name: str) -> pd.DataFrame, która zwróci ramkę danych z wczytanym zbiorem danych dostępnym w pakiecie Scikit-learn. Jako nazwę można przyjąć dowolny identyfikator, np. alias w adresie URL prowadzącym do szczegółów zbioru: https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset (alias jest dostępny po znaku #).\n",
    "\n",
    "2. Dokonać podziału podzbioru treningowego w stosunku 80%:20% przeznaczając 20% na podzbiór walidacyjny, gdzie pozostałe 80% nadal będzie stanowiło podzbiór treningowy, lecz okrojony.\n",
    "\n",
    "3. Dla przeprowadzonych podziałów metodą prostą oraz warstwową (dla każdego podziału) przygotować histogram prezentujący rozkład liczebności wartości atrybutu decyzyjnego zarówno w podzbiorze treningowym, jak i testowym.\n",
    "\n",
    "4. Dokonać podziału oryginalnego zbioru danych metodą warstwową względem innego atrybutu (obecnego w pierwotnej wersji zbioru). Jakiego atrybutu i dlaczego warto użyć? Dopuszczalne są niewielkie i uzasadnione zmiany wartości atrybutu stanowiącego źródło proporcji podziału."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
